# MT--Kimi翻译插件
 基于Kimi API的翻译引擎，支持多语言互译

# 关于模型选择
 1.Moonshot V1 系列（旧版）
   
   这是早期模型，按上下文长度分档，目前已被 K2 系列全面超越：V1 8K/32K/128K：仅支持纯文本，编程和推理能力较弱，不建议用于翻译插件。
 
 2.Kimi K2 系列（主流）
  
  （1）基础非思考模型
      这些模型不会显示思考过程，响应速度快
| 模型 | 上下文 | 特点 | 适用场景 |
|------|--------|------|----------|
| K2 0711 | 128K | 2025年7月版，基础编程能力 | 已被0905取代，不建议选 |
| K2 0905 | 256K | 9月升级版，编程能力↑，前端代码更美观 | 翻译长文档首选，性价比高 |
| K2 Turbo | 256K | 速度优化版，60-100 Token/s | 需要快速翻译大量短文本 | 
 
 （2）思考模型（Chain-of-Thought）
     这些模型会内部长思考（类似 DeepSeek R1），适合复杂推理但成本高、速度慢
| 模型 | 特点 | 适用场景 |
|------|------|----------|
| K2 Thinking | 支持200-300步工具调用，深度推理，但慢且贵 | 复杂技术文档、专业术语极多的翻译 |
| K2 Thinking Turbo | Thinking 的高速版，平衡推理和速度 | 需要一定推理能力又不想等太久 |

3.旗舰全能模型
 | 模型 | 特点 |
|------|------|
| K2.5 | 最新最强，支持多模态（图片+文本），思考/非思考双模式切换，Agent 和 Coding 能力最强，开源 SoTA 表现 |

# 翻译插件选型建议
（1）性价比首选：K2 0905 或 K2 Turbo
 
    256K 上下文足够翻译整本小说或大型 JSON 文件
 
    非思考模式不会"过度解读"原文，术语一致性更好
（2）高质量首选：K2.5
 
    如果翻译质量要求高且能接受价格，选这个
 
    支持图文混排翻译（如果 Mt 管理器需要翻译带图片的资源文件）
（3）不推荐：
 
    V1 系列：能力 outdated
 
    Thinking 系列：翻译任务通常不需要深度数学/代码推理，用 Thinking 属于"杀鸡用牛刀"，且响应慢、费用高（Thinking 模型按训练 token 额外计费）
    
    版本号含义： 0711  = 2025年7月11日发布， 0905  = 9月5日发布，数字越大越新[^0^]。

# 关于Temperature设置
  （1）建议Temperature设为0.0-0.3
      
      术语一致性：同一专业词汇不会变来变去
  
      格式保持：代码、标记符号更稳定
      
      减少"发挥"：避免AI在翻译时添加原文没有的解释

  （2）特殊调整：
| 文本类型/场景 | 温度值 | 说明 |
|-------------|--------|------|
| 文学/小说翻译 | 0.4-0.5 | 保留语言风格 |
| 技术文档/法律文本 | 0.0-0.2 | 追求精准对应 |
| Thinking系列 | 0 | 开启后设0，让模型自己决定 |
